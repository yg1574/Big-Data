{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-49d7c4e178f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('ccd').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('credit-card-default-1000.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|CUSTID|\n",
      "+------+\n",
      "|   530|\n",
      "|    38|\n",
      "|    43|\n",
      "|    47|\n",
      "|    70|\n",
      "|    79|\n",
      "|    99|\n",
      "|   104|\n",
      "|   135|\n",
      "|   170|\n",
      "|   173|\n",
      "|   179|\n",
      "|   198|\n",
      "|   200|\n",
      "|   292|\n",
      "|   398|\n",
      "|   519|\n",
      "|   653|\n",
      "|   664|\n",
      "|   703|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('CUSTID').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Removing the junk characters from some of the rows using FILTER operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(df['CUSTID'] != 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|SEX|\n",
      "+---+\n",
      "|  2|\n",
      "|  2|\n",
      "|  1|\n",
      "|  2|\n",
      "|  1|\n",
      "|  2|\n",
      "|  F|\n",
      "|  2|\n",
      "|  2|\n",
      "|  2|\n",
      "|  2|\n",
      "|  2|\n",
      "|  2|\n",
      "|  2|\n",
      "|  2|\n",
      "|  2|\n",
      "|  2|\n",
      "|  2|\n",
      "|  1|\n",
      "|  2|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df['SEX']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Here some of values in the sex column are M or 1 for Male & F or 2 for Female so coverting all the values to numeric values of 1 or 2 using the WHEN operation. Also creating another column SEX_FINAL using WITHCOLUMN operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"SEX_NEW\",when(df[\"SEX\"] == 'F', 2).otherwise(df['SEX']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"SEX_FINAL\",when(df[\"SEX_NEW\"] == 'M', 1).otherwise(df['SEX_NEW']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CUSTID',\n",
       " 'LIMIT_BAL',\n",
       " 'SEX',\n",
       " 'EDUCATION',\n",
       " 'MARRIAGE',\n",
       " 'AGE',\n",
       " 'PAY_1',\n",
       " 'PAY_2',\n",
       " 'PAY_3',\n",
       " 'PAY_4',\n",
       " 'PAY_5',\n",
       " 'PAY_6',\n",
       " 'BILL_AMT1',\n",
       " 'BILL_AMT2',\n",
       " 'BILL_AMT3',\n",
       " 'BILL_AMT4',\n",
       " 'BILL_AMT5',\n",
       " 'BILL_AMT6',\n",
       " 'PAY_AMT1',\n",
       " 'PAY_AMT2',\n",
       " 'PAY_AMT3',\n",
       " 'PAY_AMT4',\n",
       " 'PAY_AMT5',\n",
       " 'PAY_AMT6',\n",
       " 'DEFAULTED',\n",
       " 'SEX_NEW',\n",
       " 'SEX_FINAL']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import format_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select('CUSTID',\n",
    " 'LIMIT_BAL',\n",
    " 'SEX',\n",
    " 'EDUCATION',\n",
    " 'MARRIAGE',\n",
    " 'AGE',\n",
    " 'PAY_1',\n",
    " 'PAY_2',\n",
    " 'PAY_3',\n",
    " 'PAY_4',\n",
    " 'PAY_5',\n",
    " 'PAY_6',\n",
    " 'BILL_AMT1',\n",
    " 'BILL_AMT2',\n",
    " 'BILL_AMT3',\n",
    " 'BILL_AMT4',\n",
    " 'BILL_AMT5',\n",
    " 'BILL_AMT6',\n",
    " 'PAY_AMT1',\n",
    " 'PAY_AMT2',\n",
    " 'PAY_AMT3',\n",
    " 'PAY_AMT4',\n",
    " 'PAY_AMT5',\n",
    " 'PAY_AMT6',\n",
    " 'DEFAULTED',\n",
    " 'SEX_NEW',\n",
    " 'SEX_FINAL',format_number(df['AGE'],2).alias('AGE_NEW'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|AGE_NEW|\n",
      "+-------+\n",
      "|  21.00|\n",
      "|  22.00|\n",
      "|  22.00|\n",
      "|  22.00|\n",
      "|  22.00|\n",
      "|  22.00|\n",
      "|  22.00|\n",
      "|  22.00|\n",
      "|  22.00|\n",
      "|  22.00|\n",
      "|  22.00|\n",
      "|  22.00|\n",
      "|  22.00|\n",
      "|  22.00|\n",
      "|  22.00|\n",
      "|  22.00|\n",
      "|  22.00|\n",
      "|  22.00|\n",
      "|  22.00|\n",
      "|  22.00|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df['AGE_NEW']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Creating a new age variable AGE_FINAL where the age is rounded off to the 10's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"AGE_NEW1\", df['AGE_NEW']/10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here FUNC operation is used to round the value in the AGE_NEW1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"AGE_NEW2\", func.round(df['AGE_NEW1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"AGE_FINAL\",df['AGE_NEW2']*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Creating new columns for averages such as AVG_BILL, AVG_PAY & PER_PAY using the WITHCOLUMN operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"AVG_BILL\",(df[\"BILL_AMT1\"]+df[\"BILL_AMT2\"]+df[\"BILL_AMT3\"]+df[\"BILL_AMT4\"]+df[\"BILL_AMT5\"]+df[\"BILL_AMT6\"])/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"AVG_PAY\",(df[\"PAY_AMT1\"]+df[\"PAY_AMT2\"]+df[\"PAY_AMT3\"]+df[\"PAY_AMT4\"]+df[\"PAY_AMT5\"]+df[\"PAY_AMT6\"])/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"PER_PAY\",df[\"AVG_BILL\"]/df[\"AVG_PAY\"]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting negative values to positive values using using the FUNC operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"PAY_NEW1\", func.abs(df['PAY_1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"PAY_NEW2\", func.abs(df['PAY_2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"PAY_NEW3\", func.abs(df['PAY_3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"PAY_NEW4\", func.abs(df['PAY_4']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"PAY_NEW5\", func.abs(df['PAY_5']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"PAY_NEW6\", func.abs(df['PAY_6']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"AVG_DUR\",(df[\"PAY_NEW1\"]+df[\"PAY_NEW2\"]+df[\"PAY_NEW3\"]+df[\"PAY_NEW4\"]+df[\"PAY_NEW5\"]+df[\"PAY_NEW6\"])/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CUSTID',\n",
       " 'LIMIT_BAL',\n",
       " 'SEX',\n",
       " 'EDUCATION',\n",
       " 'MARRIAGE',\n",
       " 'AGE',\n",
       " 'PAY_1',\n",
       " 'PAY_2',\n",
       " 'PAY_3',\n",
       " 'PAY_4',\n",
       " 'PAY_5',\n",
       " 'PAY_6',\n",
       " 'BILL_AMT1',\n",
       " 'BILL_AMT2',\n",
       " 'BILL_AMT3',\n",
       " 'BILL_AMT4',\n",
       " 'BILL_AMT5',\n",
       " 'BILL_AMT6',\n",
       " 'PAY_AMT1',\n",
       " 'PAY_AMT2',\n",
       " 'PAY_AMT3',\n",
       " 'PAY_AMT4',\n",
       " 'PAY_AMT5',\n",
       " 'PAY_AMT6',\n",
       " 'DEFAULTED',\n",
       " 'SEX_NEW',\n",
       " 'SEX_FINAL',\n",
       " 'AGE_NEW',\n",
       " 'AGE_NEW1',\n",
       " 'AGE_NEW2',\n",
       " 'AGE_FINAL',\n",
       " 'AVG_BILL',\n",
       " 'AVG_PAY',\n",
       " 'PER_PAY',\n",
       " 'PAY_NEW1',\n",
       " 'PAY_NEW2',\n",
       " 'PAY_NEW3',\n",
       " 'PAY_NEW4',\n",
       " 'PAY_NEW5',\n",
       " 'PAY_NEW6',\n",
       " 'AVG_DUR']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+---+---------+--------+---+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+---------+--------+--------+--------+--------+--------+--------+---------+-------+---------+-------+--------+--------+---------+------------------+------------------+------------------+--------+--------+--------+--------+--------+--------+------------------+\n",
      "|CUSTID|LIMIT_BAL|SEX|EDUCATION|MARRIAGE|AGE|PAY_1|PAY_2|PAY_3|PAY_4|PAY_5|PAY_6|BILL_AMT1|BILL_AMT2|BILL_AMT3|BILL_AMT4|BILL_AMT5|BILL_AMT6|PAY_AMT1|PAY_AMT2|PAY_AMT3|PAY_AMT4|PAY_AMT5|PAY_AMT6|DEFAULTED|SEX_NEW|SEX_FINAL|AGE_NEW|AGE_NEW1|AGE_NEW2|AGE_FINAL|          AVG_BILL|           AVG_PAY|           PER_PAY|PAY_NEW1|PAY_NEW2|PAY_NEW3|PAY_NEW4|PAY_NEW5|PAY_NEW6|           AVG_DUR|\n",
      "+------+---------+---+---------+--------+---+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+---------+--------+--------+--------+--------+--------+--------+---------+-------+---------+-------+--------+--------+---------+------------------+------------------+------------------+--------+--------+--------+--------+--------+--------+------------------+\n",
      "|   530|    20000|  2|        2|       2| 21|   -1|   -1|    2|    2|   -2|   -2|        0|        0|        0|        0|        0|        0|       0|       0|       0|       0|  162000|       0|        0|      2|        2|  21.00|     2.1|     2.0|     20.0|               0.0|           27000.0|               0.0|       1|       1|       2|       2|       2|       2|1.6666666666666667|\n",
      "|    38|    60000|  2|        2|       2| 22|    0|    0|    0|    0|   -2|   -2|        0|        0|        0|        0|        0|        0|       0|       0|       0|       0|       0|    1576|        0|      2|        2|  22.00|     2.2|     2.0|     20.0|               0.0| 262.6666666666667|               0.0|       0|       0|       0|       0|       2|       2|0.6666666666666666|\n",
      "|    43|    10000|  1|        2|       2| 22|    0|    0|    0|    0|   -2|   -2|        0|        0|        0|        0|        0|        0|       0|       0|       0|       0|       0|    1500|        0|      1|        1|  22.00|     2.2|     2.0|     20.0|               0.0|             250.0|               0.0|       0|       0|       0|       0|       2|       2|0.6666666666666666|\n",
      "|    47|    20000|  2|        1|       2| 22|    0|    0|    2|   -1|    0|   -1|     1131|      291|      582|      291|        0|      291|     291|     582|       0|       0|  130291|     651|        0|      2|        2|  22.00|     2.2|     2.0|     20.0|             431.0|21969.166666666668|1.9618404582179567|       0|       0|       2|       1|       0|       1|0.6666666666666666|\n",
      "|    70|    20000|  1|        4|       2| 22|    2|    0|    0|    0|   -1|   -1|     1692|    13250|      433|     1831|        0|     2891|   13250|     433|    1831|       0|    2891|  153504|        0|      1|        1|  22.00|     2.2|     2.0|     20.0|            3349.5|           28651.5|11.690487409036177|       2|       0|       0|       0|       1|       1|0.6666666666666666|\n",
      "|    79|    30000|  2|        2|       2| 22|    0|    0|    0|    0|   -2|   -2|     1544|     1648|     1284|     1088|      892|     -304|    1300|    1000|    1000|    1000|     304|   39544|        0|      2|        2|  22.00|     2.2|     2.0|     20.0|1025.3333333333333|            7358.0| 13.93494609042312|       0|       0|       0|       0|       2|       2|0.6666666666666666|\n",
      "|    99|    50000|  F|        3|       1| 22|    0|    0|    0|    0|   -1|   -1|        0|        0|        0|        0|      166|      541|       0|       0|       0|     166|     543|    4268|        0|      2|        2|  22.00|     2.2|     2.0|     20.0|117.83333333333333|             829.5| 14.20534458509142|       0|       0|       0|       0|       1|       1|0.3333333333333333|\n",
      "|   104|    50000|  2|        3|       2| 22|    0|    0|    0|    0|   -1|   -1|      780|        0|      780|      390|      390|      500|       0|     780|       0|     390|     500|   18300|        0|      2|        2|  22.00|     2.2|     2.0|     20.0| 473.3333333333333|3328.3333333333335|14.221331997996995|       0|       0|       0|       0|       1|       1|0.3333333333333333|\n",
      "|   135|    30000|  2|        2|       2| 22|    0|    0|    0|    0|   -2|   -2|       92|       92|       92|        0|       92|        0|      92|      92|       0|      92|       0|    1883|        0|      2|        2|  22.00|     2.2|     2.0|     20.0|61.333333333333336| 359.8333333333333|17.044928207503478|       0|       0|       0|       0|       2|       2|0.6666666666666666|\n",
      "|   170|    50000|  2|        2|       2| 22|    0|    0|    0|    0|    2|   -1|     -190|    -9850|    -9850|    10311|    10161|     7319|       0|       0|   20161|       0|    7319|   13899|        0|      2|        2|  22.00|     2.2|     2.0|     20.0|1316.8333333333333|            6896.5|19.094226540032384|       0|       0|       0|       0|       2|       1|               0.5|\n",
      "|   173|    50000|  2|        2|       2| 22|   -1|    0|    0|    0|   -1|   -1|        0|        0|      250|      123|      789|     1222|       0|     250|       0|     789|    1222|    9616|        0|      2|        2|  22.00|     2.2|     2.0|     20.0| 397.3333333333333|            1979.5|20.072408857455585|       1|       0|       0|       0|       1|       1|               0.5|\n",
      "|   179|    20000|  2|        2|       2| 22|    0|    0|    0|    0|   -1|   -1|        0|        0|        0|        0|      595|        0|       0|       0|       0|     595|       0|    2370|        0|      2|        2|  22.00|     2.2|     2.0|     20.0| 99.16666666666667| 494.1666666666667| 20.06745362563238|       0|       0|       0|       0|       1|       1|0.3333333333333333|\n",
      "|   198|    20000|  2|        1|       2| 22|    0|    0|    0|    0|   -2|   -1|      -54|      273|       19|     -254|     -527|     1096|     600|      19|       0|       0|    1896|       0|        0|      2|        2|  22.00|     2.2|     2.0|     20.0| 92.16666666666667| 419.1666666666667|21.988071570576544|       0|       0|       0|       0|       2|       1|               0.5|\n",
      "|   200|    30000|  2|        3|       2| 22|    1|    2|    2|    0|   -2|   -2|      -14|     2568|     -387|     -387|     -387|      113|    2582|       0|       0|       0|     500|    2515|        0|      2|        2|  22.00|     2.2|     2.0|     20.0|             251.0| 932.8333333333334| 26.90727175272467|       1|       2|       2|       0|       2|       2|               1.5|\n",
      "|   292|    50000|  2|        2|       2| 22|    1|   -2|   -2|   -2|   -2|   -2|     -288|     -288|     -288|     -288|     -288|     2124|       0|       0|       0|       0|    2412|       0|        0|      2|        2|  22.00|     2.2|     2.0|     20.0|             114.0|             402.0| 28.35820895522388|       1|       2|       2|       2|       2|       2|1.8333333333333333|\n",
      "|   398|    50000|  2|        2|       2| 22|   -2|   -2|   -2|   -2|   -1|   -1|      412|      138|     2299|     1251|     1206|     1151|     138|    2299|    1251|    1206|    1151|   15816|        0|      2|        2|  22.00|     2.2|     2.0|     20.0|1076.1666666666667|            3643.5|29.536617721055762|       2|       2|       2|       2|       1|       1|1.6666666666666667|\n",
      "|   519|    10000|  2|        2|       2| 22|    1|    2|    0|    0|    0|   -1|     1371|      796|      398|      796|      398|      716|     796|       0|     796|       0|     716|   12111|        0|      2|        2|  22.00|     2.2|     2.0|     20.0| 745.8333333333334|2403.1666666666665|31.035439350856514|       1|       2|       0|       0|       0|       1|0.6666666666666666|\n",
      "|   653|    20000|  2|        1|       2| 22|    0|    0|    0|    0|   -2|   -2|      158|        0|        0|        0|        0|      612|       0|       0|       0|       0|     612|    1863|        0|      2|        2|  22.00|     2.2|     2.0|     20.0|128.33333333333334|             412.5| 31.11111111111111|       0|       0|       0|       0|       2|       2|0.6666666666666666|\n",
      "|   664|    50000|  1|        1|       2| 22|    0|    0|    0|    0|   -1|   -1|     2000|     1000|     2125|     2125|     1000|     2125|       0|    2125|    2125|    1000|    2125|   23250|        0|      1|        1|  22.00|     2.2|     2.0|     20.0|1729.1666666666667| 5104.166666666667| 33.87755102040816|       0|       0|       0|       0|       1|       1|0.3333333333333333|\n",
      "|   703|    10000|  2|        3|       2| 22|    0|    0|    0|    0|   -2|   -1|        0|        0|        0|        0|        0|      150|       0|       0|       0|       0|     300|     102|        0|      2|        2|  22.00|     2.2|     2.0|     20.0|              25.0|              67.0|  37.3134328358209|       0|       0|       0|       0|       2|       1|               0.5|\n",
      "+------+---------+---+---------+--------+---+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+---------+--------+--------+--------+--------+--------+--------+---------+-------+---------+-------+--------+--------+---------+------------------+------------------+------------------+--------+--------+--------+--------+--------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CUSTID',\n",
       " 'LIMIT_BAL',\n",
       " 'SEX',\n",
       " 'EDUCATION',\n",
       " 'MARRIAGE',\n",
       " 'AGE',\n",
       " 'PAY_1',\n",
       " 'PAY_2',\n",
       " 'PAY_3',\n",
       " 'PAY_4',\n",
       " 'PAY_5',\n",
       " 'PAY_6',\n",
       " 'BILL_AMT1',\n",
       " 'BILL_AMT2',\n",
       " 'BILL_AMT3',\n",
       " 'BILL_AMT4',\n",
       " 'BILL_AMT5',\n",
       " 'BILL_AMT6',\n",
       " 'PAY_AMT1',\n",
       " 'PAY_AMT2',\n",
       " 'PAY_AMT3',\n",
       " 'PAY_AMT4',\n",
       " 'PAY_AMT5',\n",
       " 'PAY_AMT6',\n",
       " 'DEFAULTED',\n",
       " 'SEX_NEW',\n",
       " 'SEX_FINAL',\n",
       " 'AGE_NEW',\n",
       " 'AGE_NEW1',\n",
       " 'AGE_NEW2',\n",
       " 'AGE_FINAL',\n",
       " 'AVG_BILL',\n",
       " 'AVG_PAY',\n",
       " 'PER_PAY',\n",
       " 'PAY_NEW1',\n",
       " 'PAY_NEW2',\n",
       " 'PAY_NEW3',\n",
       " 'PAY_NEW4',\n",
       " 'PAY_NEW5',\n",
       " 'PAY_NEW6',\n",
       " 'AVG_DUR']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CUSTID: string (nullable = true)\n",
      " |-- LIMIT_BAL: integer (nullable = true)\n",
      " |-- SEX: string (nullable = true)\n",
      " |-- EDUCATION: integer (nullable = true)\n",
      " |-- MARRIAGE: integer (nullable = true)\n",
      " |-- AGE: integer (nullable = true)\n",
      " |-- PAY_1: integer (nullable = true)\n",
      " |-- PAY_2: integer (nullable = true)\n",
      " |-- PAY_3: integer (nullable = true)\n",
      " |-- PAY_4: integer (nullable = true)\n",
      " |-- PAY_5: integer (nullable = true)\n",
      " |-- PAY_6: integer (nullable = true)\n",
      " |-- BILL_AMT1: integer (nullable = true)\n",
      " |-- BILL_AMT2: integer (nullable = true)\n",
      " |-- BILL_AMT3: integer (nullable = true)\n",
      " |-- BILL_AMT4: integer (nullable = true)\n",
      " |-- BILL_AMT5: integer (nullable = true)\n",
      " |-- BILL_AMT6: integer (nullable = true)\n",
      " |-- PAY_AMT1: integer (nullable = true)\n",
      " |-- PAY_AMT2: integer (nullable = true)\n",
      " |-- PAY_AMT3: integer (nullable = true)\n",
      " |-- PAY_AMT4: integer (nullable = true)\n",
      " |-- PAY_AMT5: integer (nullable = true)\n",
      " |-- PAY_AMT6: integer (nullable = true)\n",
      " |-- DEFAULTED: integer (nullable = true)\n",
      " |-- SEX_NEW: string (nullable = true)\n",
      " |-- SEX_FINAL: string (nullable = true)\n",
      " |-- AGE_NEW: string (nullable = true)\n",
      " |-- AGE_NEW1: double (nullable = true)\n",
      " |-- AGE_NEW2: double (nullable = true)\n",
      " |-- AGE_FINAL: double (nullable = true)\n",
      " |-- AVG_BILL: double (nullable = true)\n",
      " |-- AVG_PAY: double (nullable = true)\n",
      " |-- PER_PAY: double (nullable = true)\n",
      " |-- PAY_NEW1: integer (nullable = true)\n",
      " |-- PAY_NEW2: integer (nullable = true)\n",
      " |-- PAY_NEW3: integer (nullable = true)\n",
      " |-- PAY_NEW4: integer (nullable = true)\n",
      " |-- PAY_NEW5: integer (nullable = true)\n",
      " |-- PAY_NEW6: integer (nullable = true)\n",
      " |-- AVG_DUR: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the above Schema we can see that SEX_FINAL is a string so coverting it to an integer using the CAST(INTERGERTYPE) operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "df = df.withColumn(\"SEX_LAST\",df[\"SEX_FINAL\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CUSTID: string (nullable = true)\n",
      " |-- LIMIT_BAL: integer (nullable = true)\n",
      " |-- SEX: string (nullable = true)\n",
      " |-- EDUCATION: integer (nullable = true)\n",
      " |-- MARRIAGE: integer (nullable = true)\n",
      " |-- AGE: integer (nullable = true)\n",
      " |-- PAY_1: integer (nullable = true)\n",
      " |-- PAY_2: integer (nullable = true)\n",
      " |-- PAY_3: integer (nullable = true)\n",
      " |-- PAY_4: integer (nullable = true)\n",
      " |-- PAY_5: integer (nullable = true)\n",
      " |-- PAY_6: integer (nullable = true)\n",
      " |-- BILL_AMT1: integer (nullable = true)\n",
      " |-- BILL_AMT2: integer (nullable = true)\n",
      " |-- BILL_AMT3: integer (nullable = true)\n",
      " |-- BILL_AMT4: integer (nullable = true)\n",
      " |-- BILL_AMT5: integer (nullable = true)\n",
      " |-- BILL_AMT6: integer (nullable = true)\n",
      " |-- PAY_AMT1: integer (nullable = true)\n",
      " |-- PAY_AMT2: integer (nullable = true)\n",
      " |-- PAY_AMT3: integer (nullable = true)\n",
      " |-- PAY_AMT4: integer (nullable = true)\n",
      " |-- PAY_AMT5: integer (nullable = true)\n",
      " |-- PAY_AMT6: integer (nullable = true)\n",
      " |-- DEFAULTED: integer (nullable = true)\n",
      " |-- SEX_NEW: string (nullable = true)\n",
      " |-- SEX_FINAL: string (nullable = true)\n",
      " |-- AGE_NEW: string (nullable = true)\n",
      " |-- AGE_NEW1: double (nullable = true)\n",
      " |-- AGE_NEW2: double (nullable = true)\n",
      " |-- AGE_FINAL: double (nullable = true)\n",
      " |-- AVG_BILL: double (nullable = true)\n",
      " |-- AVG_PAY: double (nullable = true)\n",
      " |-- PER_PAY: double (nullable = true)\n",
      " |-- PAY_NEW1: integer (nullable = true)\n",
      " |-- PAY_NEW2: integer (nullable = true)\n",
      " |-- PAY_NEW3: integer (nullable = true)\n",
      " |-- PAY_NEW4: integer (nullable = true)\n",
      " |-- PAY_NEW5: integer (nullable = true)\n",
      " |-- PAY_NEW6: integer (nullable = true)\n",
      " |-- AVG_DUR: double (nullable = true)\n",
      " |-- SEX_LAST: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"AGE\",df[\"AGE_FINAL\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"BILL\",df[\"AVG_BILL\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"PAY\",df[\"AVG_PAY\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"PERCENTAGE_PAY\",df[\"PER_PAY\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"DURATION\",df[\"AVG_DUR\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new data frame using the important features to be used for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.select(['LIMIT_BAL',\n",
    " 'EDUCATION',\n",
    " 'MARRIAGE',\n",
    " 'SEX_LAST',\n",
    " 'AGE',\n",
    " 'BILL',\n",
    " 'PAY',\n",
    " 'PERCENTAGE_PAY','DEFAULTED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some of the values are null so filling those values by 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = new_df.fillna(0, subset=['LIMIT_BAL',\n",
    " 'EDUCATION',\n",
    " 'MARRIAGE',\n",
    " 'SEX_LAST',\n",
    " 'AGE',\n",
    " 'BILL',\n",
    " 'PAY',\n",
    " 'PERCENTAGE_PAY','DEFAULTED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------+--------+---+----+-----+--------------+---------+\n",
      "|LIMIT_BAL|EDUCATION|MARRIAGE|SEX_LAST|AGE|BILL|  PAY|PERCENTAGE_PAY|DEFAULTED|\n",
      "+---------+---------+--------+--------+---+----+-----+--------------+---------+\n",
      "|    20000|        2|       2|       2| 20|   0|27000|             0|        0|\n",
      "|    60000|        2|       2|       2| 20|   0|  262|             0|        0|\n",
      "|    10000|        2|       2|       1| 20|   0|  250|             0|        0|\n",
      "|    20000|        1|       2|       2| 20| 431|21969|             1|        0|\n",
      "|    20000|        4|       2|       1| 20|3349|28651|            11|        0|\n",
      "|    30000|        2|       2|       2| 20|1025| 7358|            13|        0|\n",
      "|    50000|        3|       1|       2| 20| 117|  829|            14|        0|\n",
      "|    50000|        3|       2|       2| 20| 473| 3328|            14|        0|\n",
      "|    30000|        2|       2|       2| 20|  61|  359|            17|        0|\n",
      "|    50000|        2|       2|       2| 20|1316| 6896|            19|        0|\n",
      "|    50000|        2|       2|       2| 20| 397| 1979|            20|        0|\n",
      "|    20000|        2|       2|       2| 20|  99|  494|            20|        0|\n",
      "|    20000|        1|       2|       2| 20|  92|  419|            21|        0|\n",
      "|    30000|        3|       2|       2| 20| 251|  932|            26|        0|\n",
      "|    50000|        2|       2|       2| 20| 114|  402|            28|        0|\n",
      "|    50000|        2|       2|       2| 20|1076| 3643|            29|        0|\n",
      "|    10000|        2|       2|       2| 20| 745| 2403|            31|        0|\n",
      "|    20000|        1|       2|       2| 20| 128|  412|            31|        0|\n",
      "|    50000|        1|       2|       1| 20|1729| 5104|            33|        0|\n",
      "|    10000|        3|       2|       2| 20|  25|   67|            37|        0|\n",
      "+---------+---------+--------+--------+---+----+-----+--------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using VECTORASSEMBLER converting the column values in a list called features of each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['LIMIT_BAL',\n",
    " 'EDUCATION',\n",
    " 'MARRIAGE',\n",
    " 'SEX_LAST',\n",
    " 'AGE',\n",
    " 'BILL',\n",
    " 'PAY',\n",
    " 'PERCENTAGE_PAY'],outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSFORM operation is used to carry out the action metioned above as Apache Spark supports lazy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = assembler.transform(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|            features|DEFAULTED|\n",
      "+--------------------+---------+\n",
      "|[20000.0,2.0,2.0,...|        0|\n",
      "|[60000.0,2.0,2.0,...|        0|\n",
      "|[10000.0,2.0,2.0,...|        0|\n",
      "|[20000.0,1.0,2.0,...|        0|\n",
      "|[20000.0,4.0,2.0,...|        0|\n",
      "|[30000.0,2.0,2.0,...|        0|\n",
      "|[50000.0,3.0,1.0,...|        0|\n",
      "|[50000.0,3.0,2.0,...|        0|\n",
      "|[30000.0,2.0,2.0,...|        0|\n",
      "|[50000.0,2.0,2.0,...|        0|\n",
      "|[50000.0,2.0,2.0,...|        0|\n",
      "|[20000.0,2.0,2.0,...|        0|\n",
      "|[20000.0,1.0,2.0,...|        0|\n",
      "|[30000.0,3.0,2.0,...|        0|\n",
      "|[50000.0,2.0,2.0,...|        0|\n",
      "|[50000.0,2.0,2.0,...|        0|\n",
      "|[10000.0,2.0,2.0,...|        0|\n",
      "|[20000.0,1.0,2.0,...|        0|\n",
      "|[50000.0,1.0,2.0,...|        0|\n",
      "|[10000.0,3.0,2.0,...|        0|\n",
      "+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.select('features','DEFAULTED').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new DataFrame data containing only features and the final label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = final_data.select('features','DEFAULTED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|         DEFAULTED|\n",
      "+-------+------------------+\n",
      "|  count|               709|\n",
      "|   mean|0.4118476727785614|\n",
      "| stddev|0.4925152777300845|\n",
      "|    min|                 0|\n",
      "|    max|                 1|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|          DEFAULTED|\n",
      "+-------+-------------------+\n",
      "|  count|                291|\n",
      "|   mean|0.38144329896907214|\n",
      "| stddev| 0.4865777529901479|\n",
      "|    min|                  0|\n",
      "|    max|                  1|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier,RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Decision Tree Classifier and Random Forest Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(labelCol='DEFAULTED',featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(numTrees=100, labelCol='DEFAULTED',featuresCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the models on the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_model = dtc.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model = rfc.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carrying out the prediction on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_preds = dtc_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_preds = rfc_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the ROC value using BINARYCLASSIFICATIONEVALUATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_eval = BinaryClassificationEvaluator(labelCol='DEFAULTED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC:\n",
      "0.6531531531531531\n"
     ]
    }
   ],
   "source": [
    "print('DTC:')\n",
    "print(my_eval.evaluate(dtc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC:\n",
      "0.7796296296296293\n"
     ]
    }
   ],
   "source": [
    "print('RFC:')\n",
    "print(my_eval.evaluate(rfc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the ACCURACY using MULTICLASSCLASSIFICATIONEVALUATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_eval = MulticlassClassificationEvaluator(metricName='accuracy',labelCol='DEFAULTED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC:\n",
      "0.7044673539518901\n"
     ]
    }
   ],
   "source": [
    "print('DTC:')\n",
    "print(multi_eval.evaluate(dtc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC:\n",
      "0.7285223367697594\n"
     ]
    }
   ],
   "source": [
    "print('RFC:')\n",
    "print(multi_eval.evaluate(rfc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
